{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ebd8a4d-6937-4ad6-9c93-fa944fb389c1",
   "metadata": {},
   "source": [
    "# Climate indicator forecasts over Vanuatu using CMIP6 data\n",
    "\n",
    "In this tutorial, we'll cover the following:\n",
    "- How to select climate datasets from the CMIP6 archive\n",
    "- Loading CMIP6 data stored in the Zarr format\n",
    "- Calculate climate indices for extreme weather forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6df43b-d752-43f2-903c-c8eff2a96d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba uninstall -y odc-loader\n",
    "!mamba install -y cartopy obstore 'zarr>=3' 'python=3.11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7533f0e-5dd1-423a-9a04-8ed755d180a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import dask.diagnostics\n",
    "import matplotlib.pyplot as plt\n",
    "import obstore\n",
    "import obstore.auth.planetary_computer\n",
    "import pandas as pd\n",
    "import planetary_computer\n",
    "import pystac_client\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import xarray as xr\n",
    "import xclim\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc520e32-204f-4f92-bdec-4f678160d6de",
   "metadata": {},
   "source": [
    "## Part 1: Getting cloud hosted CMIP6 data\n",
    "\n",
    "The [Coupled Model Intercomparison Project Phase 6 (CMIP6)](https://en.wikipedia.org/wiki/CMIP6#CMIP_Phase_6)\n",
    "dataset is a rich archive of modelling experiments carried out to predict the climate change impacts.\n",
    "The datasets are stored using the [Zarr](https://zarr.dev) format, and we'll go over how to access it.\n",
    "\n",
    "**Note**: This section was adapted from https://tutorial.xarray.dev/intermediate/remote_data/cmip6-cloud.html\n",
    "\n",
    "Sources:\n",
    "- https://esgf-node.llnl.gov/search/cmip6/\n",
    "- CMIP6 data hosted on Google Cloud - https://console.cloud.google.com/marketplace/details/noaa-public/cmip6\n",
    "- Pangeo/ESGF Cloud Data Access tutorial - https://pangeo-data.github.io/pangeo-cmip6-cloud/accessing_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12400d-ab5e-420e-b9f5-b61e083dc9ce",
   "metadata": {},
   "source": [
    "First, let's open a CSV containing the list of CMIP6 datasets available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9f94c-dbe3-4151-8ee7-fa182724810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://cmip6.storage.googleapis.com/pangeo-cmip6.csv\")\n",
    "print(f\"Number of rows: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb263332-dc60-4bd1-9ef3-cf9612cf09a1",
   "metadata": {},
   "source": [
    "Over 500,000 rows! Let's filter it down to the variable and experiment\n",
    "we're interested in, e.g. daily max near-surface air temperature.\n",
    "\n",
    "For the `variable_id`, you can look it up given some keyword at\n",
    "https://docs.google.com/spreadsheets/d/1UUtoz6Ofyjlpx5LdqhKcwHFz2SGoTQV2_yekHyMfL9Y\n",
    "\n",
    "For the `experiment_id`, download the spreadsheet from\n",
    "https://github.com/ES-DOC/esdoc-docs/blob/master/cmip6/experiments/spreadsheet/experiments.xlsx,\n",
    "go to the 'experiment' tab, and find the one you're interested in.\n",
    "\n",
    "Another good place to find the right model runs is https://esgf-node.llnl.gov/search/cmip6\n",
    "(once you get your head around the acronyms and short names)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b435c14-fd56-481c-b5f4-781794a1cc1a",
   "metadata": {},
   "source": [
    "Below, we'll filter to CMIP6 experiments matching:\n",
    "- Daily Maximum Near-Surface Air Temperature [K] (variable_id: `tasmax`)\n",
    "  - Alternatively, you can choose `pr` to get precipitation\n",
    "- Shared Socioeconomic Pathway 3 (experiment_id: `ssp370`)\n",
    "  - Alternatively, you can also try `ssp585` for the worst case scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe50e53-b02f-4a84-bc4a-e1934fe32661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tasmax = df.query(\"variable_id == 'tasmax' & experiment_id == 'ssp370'\")\n",
    "df_tasmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddfad3e-d4de-4c0a-be6f-53f1f7928f51",
   "metadata": {},
   "source": [
    "There's 376 modelled scenarios for SSP3.\n",
    "Let's just get the URL to the last one in the list for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515186d-8571-439a-b5a8-b8b56aab77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tasmax.zstore.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68bcfbb-24c9-420d-b297-44c678b7f8ce",
   "metadata": {},
   "source": [
    "## Part 2: Reading from the remote Zarr store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5660d-bd46-44f6-8f6d-a62947b6f2c4",
   "metadata": {},
   "source": [
    "In many cases, you'll need to first connect to the cloud provider.\n",
    "The CMIP6 dataset allows anonymous access, but for some cases,\n",
    "you may need to authentication.\n",
    "\n",
    "We'll connect to the CMIP6 Zarr store on Google Cloud using\n",
    "[`zarr.storage.ObjectStore`](https://zarr.readthedocs.io/en/v3.1.0/user-guide/storage.html#object-store):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6d5e3-35a0-4c31-a1b8-96258cf50974",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gcs_store = obstore.store.from_url(\n",
    "    url=\"gs://cmip6/CMIP6/ScenarioMIP/CMCC/CMCC-ESM2/ssp370/r1i1p1f1/day/tasmax/gn/v20210202/\",\n",
    "    skip_signature=True,\n",
    ")\n",
    "store = zarr.storage.ObjectStore(store=gcs_store, read_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b694baac-9259-4de8-8eae-ac3cb653d894",
   "metadata": {},
   "source": [
    "Once the Zarr store connection is in place, we can open it into an `xarray.Dataset` like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6d289-a852-4216-a3b6-4483d5ff2854",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(store=store, consolidated=True, zarr_format=2)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a5958-517b-4215-8c02-b1083b4b4fe2",
   "metadata": {},
   "source": [
    "### Selecting time slices\n",
    "\n",
    "Let's say we want to calculate temperature changes between\n",
    "2025 and 2050. We can access just the specific time points\n",
    "needed using [`xr.Dataset.sel`](https://docs.xarray.dev/en/stable/generated/xarray.Dataset.sel.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1101b455-ba65-4cab-a3b6-bf2601958400",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmax_2025jan = ds.tasmax.sel(time=\"2025-01-16\").squeeze()\n",
    "tasmax_2050dec = ds.tasmax.sel(time=\"2050-12-16\").squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d90a2-9883-41da-b26c-7b5547a15270",
   "metadata": {},
   "source": [
    "Temperature change would just be 2050 minus 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5fa1ee-260c-4ec4-898a-230826f9f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmax_change = tasmax_2050dec - tasmax_2025jan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e087f3b-0315-40db-ae03-a3393b49c30e",
   "metadata": {},
   "source": [
    "Note that up to this point, we have not actually downloaded any\n",
    "(big) data yet from the cloud. This is all working based on\n",
    "metadata only.\n",
    "\n",
    "To bring the data from the cloud to your local computer, call `.compute`.\n",
    "This will take a while depending on your connection speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2152e-67e7-449e-8f1a-2d64f63dedda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmax_change = tasmax_change.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5226729f-07db-4fe6-a980-9a1f630c8277",
   "metadata": {},
   "source": [
    "We can do a quick plot to show how maximum near-surface temperature\n",
    "is predicted to change between 2025-2050 (from one modelled experiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c42ed9f-fc61-4762-9765-3dd553d5c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmax_change.plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4361786-c889-4ae7-a704-dcbda50513da",
   "metadata": {},
   "source": [
    "This temperature change is for the entire planet. Let's zoom in over Vanuatu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3456827-13c2-4561-ae56-83b9b9be6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = ccrs.epsg(code=3832)  # PDC Mercator\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, subplot_kw=dict(projection=projection))\n",
    "tasmax_change.sel(lon=slice(166, 170), lat=slice(-22, -11)).plot.imshow(\n",
    "    ax=ax, transform=ccrs.PlateCarree()\n",
    ")\n",
    "ax.set_extent(extents=[166, 170, -22, -11], crs=ccrs.PlateCarree())\n",
    "ax.coastlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af08c2b",
   "metadata": {},
   "source": [
    "This CMIP6 output is very coarse, so there's only 4x11=44 pixels covering Vanuatu.\n",
    "You could try to say that the northern regions is forecasted to experience\n",
    "higher daily maximum temperatures than the South in 2050 compared to 2025,\n",
    "but it's best to get more data before jumping to these conclusions.\n",
    "Specifically:\n",
    "\n",
    "- Look at an ensemble of forecasts from different CMIP6 models\n",
    "- Potentially look at downscaled data that will show local patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb523e2-2051-486c-a7f1-561911959f1e",
   "metadata": {},
   "source": [
    "## Part 2b: Getting downscaled climate data\n",
    "\n",
    "For a small country like Vanuatu that is ~400km wide by ~800km long,\n",
    "it may be desirable to obtain higher spatial resolution projections.\n",
    "The original CMIP6 datasets have a coarse spatial resolution of\n",
    "1 arc degree or more (>100 km).\n",
    "\n",
    "There are groups that have taken these CMIP6 datasets and processed them\n",
    "using statistical downscaling + bias correction algorithms to produce\n",
    "higher spatial resolution outputs of 0.25 arc degrees (~25km) or so.\n",
    "Examples include:\n",
    "\n",
    "- Climate Impact Lab's [Global Downscaled Projections for Climate Impacts Research](https://github.com/ClimateImpactLab/downscaleCMIP6)\n",
    "- NASA Earth Exchange Global Daily Downscaled Projection ([NEX-GDDP-CMIP6](https://www.nccs.nasa.gov/services/data-collections/land-based-products/nex-gddp-cmip6))\n",
    "- Carbonplan's CMIP6 downscaled products based on [4 different methods](https://carbonplan.org/research/cmip6-downscaling-explainer)\n",
    "\n",
    "References:\n",
    "- Gergel, D. R., Malevich, S. B., McCusker, K. E., Tenezakis, E., Delgado, M. T., Fish, M. A., and Kopp, R. E.: Global Downscaled Projections for Climate Impacts Research (GDPCIR): preserving quantile trends for modeling future climate impacts, Geosci. Model Dev., 17, 191â€“227, https://doi.org/10.5194/gmd-17-191-2024, 2024.\n",
    "- TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df887d84-0d9a-4bec-94fe-b74e0367dcec",
   "metadata": {},
   "source": [
    "The examples below will use the\n",
    "[CIL-GDPCIR-CC0](https://planetarycomputer.microsoft.com/dataset/cil-gdpcir-cc0)\n",
    "dataset hosted on Planetary Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ac7fd-390f-415e-bb95-579eab82a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1/\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90aaba7-6c85-474b-85eb-ef8280d1d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSP_ID = \"ssp585\"  # \"historical\", \"ssp126\", \"ssp245\", \"ssp370\", \"ssp585\"\n",
    "search = catalog.search(\n",
    "    collections=[\"cil-gdpcir-cc0\"],  # add \"cil-gdpcir-cc-by\" for more models\n",
    "    query={\"cmip6:experiment_id\": {\"eq\": SSP_ID}},\n",
    ")\n",
    "ensemble = search.item_collection()\n",
    "len(ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70132965-e855-4d00-89a4-b9849ed5ff7e",
   "metadata": {},
   "source": [
    "Let's look at precipitation (pr).\n",
    "\n",
    "Code based on:\n",
    "- https://planetarycomputer.microsoft.com/dataset/cil-gdpcir-cc0#Ensemble-example\n",
    "- https://developmentseed.org/obstore/v0.7.1/examples/zarr/#example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9060bb0-7a7c-4249-a0bb-507ec8fca6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select this variable ID for all models in a collection\n",
    "variable_id = \"pr\"  # or \"tasmax\"\n",
    "\n",
    "datasets_by_model = []\n",
    "\n",
    "for item in tqdm.tqdm(ensemble):\n",
    "    asset = item.assets[variable_id]\n",
    "    # print(asset.href, asset.extra_fields[\"xarray:open_kwargs\"])\n",
    "\n",
    "    credential_provider = (\n",
    "        obstore.auth.planetary_computer.PlanetaryComputerCredentialProvider(\n",
    "            url=asset.href, account_name=\"rhgeuwest\"\n",
    "        )\n",
    "    )\n",
    "    azure_store = obstore.store.from_url(\n",
    "        url=asset.href, credential_provider=credential_provider\n",
    "    )\n",
    "\n",
    "    zarr_store = zarr.storage.ObjectStore(store=azure_store, read_only=True)\n",
    "    datasets_by_model.append(xr.open_zarr(store=zarr_store, chunks={}))\n",
    "\n",
    "all_datasets = xr.concat(\n",
    "    datasets_by_model,\n",
    "    dim=pd.Index([ds.attrs[\"source_id\"] for ds in datasets_by_model], name=\"model\"),\n",
    "    combine_attrs=\"drop_conflicts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd64022-1c82-47d9-a0c3-c3202671889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aaff29-d01b-492c-ad16-7b495c3c5294",
   "metadata": {},
   "source": [
    "We now have a data cube consisting of 3 models, spanning a time range from 2015 to 2100.\n",
    "Let's subset the data over Vanuatu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae6999c-8ce3-42fa-b1eb-403a2255a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_vanuatu = all_datasets.sel(lon=slice(166, 170), lat=slice(-22, -11))\n",
    "ds_vanuatu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1bcae1-3255-4b30-b680-a8b3956e5047",
   "metadata": {},
   "source": [
    "## Part 3: Compute climate indicators using `xmip`\n",
    "\n",
    "The `xmip` library allows us to compute climate indicators based on\n",
    "some statistic from raw climate values such as temperature or precipitation.\n",
    "\n",
    "We'll learn how to calculate a 'drought' indicator in this section. Specifically,\n",
    "compute [maximum consecutive dry days](https://xclim.readthedocs.io/en/stable/api_indicators.html#xclim.indicators.atmos.maximum_consecutive_dry_days)\n",
    "with threshold of <1 mm/day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf41c89-f23d-4646-976a-aa0f0b5e569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_cdd = xclim.indicators.atmos.maximum_consecutive_dry_days(\n",
    "    ds=ds_vanuatu,\n",
    "    thresh=\"1 mm/day\",\n",
    ")\n",
    "da_cdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ac916-50d4-4b39-b425-9f61e4b78824",
   "metadata": {},
   "source": [
    "We have 3 models, over 86 timesteps (2015-2100), across 44x16 pixels over Vanuatu.\n",
    "Let's compute this 'drought' indicator for one model and one year only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2ef0d7-7454-4455-b9b7-0162e74136ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.diagnostics.ProgressBar():\n",
    "    vu_cdd = da_cdd.isel(model=0, time=-1).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab60171-f2f3-49d4-a649-22ea7e18542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = ccrs.epsg(code=3832)  # PDC Mercator\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, subplot_kw=dict(projection=projection))\n",
    "vu_cdd.sel(lon=slice(166, 170), lat=slice(-22, -11)).plot.imshow(\n",
    "    ax=ax, transform=ccrs.PlateCarree()\n",
    ")\n",
    "ax.set_extent(extents=[166, 170, -22, -11], crs=ccrs.PlateCarree())\n",
    "ax.coastlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07b97e3-1862-4770-a24d-cbd638866e7f",
   "metadata": {},
   "source": [
    "Let's now compute this 'drought' indicator from 2025-2075,\n",
    "over an ensemble of three models. This will take about 5min to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee60df-d90a-4fe6-9076-083e4b33b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.diagnostics.ProgressBar():\n",
    "    vu_cdd = da_cdd.sel(time=slice(\"2025\", \"2075\")).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082269f-e043-42f6-a3fe-93113fcd17d5",
   "metadata": {},
   "source": [
    "Over the 44x16 pixels over Vanuatu, we'll get the maximum of all maximum\n",
    "consecutive dry day (cdd) values, per model. The `.max` (highest) value is taken,\n",
    "because we are interested in extreme values in terms of many dry days, but you\n",
    "could also get the `.median` statistic or `.min` (lowest) statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce9e0b-40ce-4ec1-afb3-e18e3d1ffdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdd_mean = vu_cdd.max(dim=(\"lat\", \"lon\"))\n",
    "cdd_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea3782-4675-4566-a777-d3b7839bf382",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdd_mean.plot.line(x=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f132d3-7457-447d-a0fd-5946ed81449e",
   "metadata": {},
   "source": [
    "There is a lot of variation in the 3 models over time, so let's plot the general mean\n",
    "trend, with error bands. We will convert the data from an `xarray.Dataset` to a\n",
    "`pandas.DataFrame` table before making this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0dacf-6157-4ca7-8862-7b2fa5c3b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CFTime to Python datetime\n",
    "if cdd_mean.time.dtype == \"object\":\n",
    "    cdd_mean[\"time\"] = cdd_mean.indexes[\"time\"].to_datetimeindex(time_unit=\"s\")\n",
    "\n",
    "# Convert from xarray.Dataset to pandas.DataFrame\n",
    "df_cdd = cdd_mean.to_pandas().T\n",
    "\n",
    "# Save to csv file (optional)\n",
    "df_cdd.to_csv(path_or_buf=f\"vut_consecutive_dry_days_{SSP_ID}.csv\")\n",
    "\n",
    "df_cdd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef7641-5cda-491b-afa0-2c64d00cd122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse or melt many columns (models) into one column\n",
    "df_cdd2 = df_cdd.melt(ignore_index=False)\n",
    "df_cdd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8eca48-3dce-40d5-b370-2f5c09867bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=df_cdd2, x=\"time\", y=\"value\", kind=\"line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87aa0a3-c82e-4da0-a5d0-31e42039feae",
   "metadata": {},
   "source": [
    "That's all! Hopefully this will get you started on how to handle CMIP6 climate data!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
