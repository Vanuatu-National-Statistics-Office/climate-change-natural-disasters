{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f01e98-f488-4663-9e49-2580fc03c3f8",
   "metadata": {},
   "source": [
    "# Coral Reef Health Monitoring around Vanuatu Coastline\n",
    "\n",
    "This notebook provides a step-by-step guide for identifying coral reefs and assessing their health over time using Sentinel-2 satellite imagery. Coral ecosystems are highly sensitive to environmental change, and satellite data offers a powerful way to monitor reef condition at scale.\n",
    "\n",
    "We will walk through a complete remote sensing workflow, including:\n",
    "\n",
    "1. **Obtain Top of Atmosphere Sentinel-2 imagery**: We will use provinces to get buffered coastlines as geographic selection criteria for a STAC search.\n",
    "2. **Cloud and Land Masking**: Remove clouds, shadows, and non-water pixels to isolate the marine environment.\n",
    "3. **Atmospheric Correction**: Convert raw Level-1C Sentinel-2 imagery to surface reflectance (Level-2A) using physics-based correction techniques.\n",
    "4. **Index Calculation**: Derive the *Normalized Blue-Green Index (NBGI)*, which is sensitive to benthic features like live coral, algae, and sand.\n",
    "5. **Training a Classifier**: Use labeled coral reef polygons from a vector dataset to train a Random Forest classifier on the spectral and index data.\n",
    "6. **Time Series Analysis**: Apply the trained model across the time series to generate predictions, and track trends in reef health over time.\n",
    "\n",
    "<img src = \"images/sentinel_l1c_raw_.png\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src = \"images/sentinel_l1c_DOS_.png\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src = \"images/nbgi.png\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "<img src = \"images/predictions.png\" width=\"500\" height=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70910b8c-4ebd-43b4-a557-545ff06be864",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba install --channel rapidsai --quiet --yes cuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1bbdfe-40a7-4e39-a718-f92b43b71815",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba install --channel conda-forge libgdal openjpeg gdal rasterio --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5319de5-2538-44c7-832a-30d4e32fefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba list libgdal-jp2openjpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0120e63-c9f6-47a8-99b4-c4014416877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /srv/conda/envs/notebook/lib/gdalplugins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed91f95-7831-436b-9821-30ac365a1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GDAL_DRIVER_PATH\"] = \"/srv/conda/envs/notebook/lib/gdalplugins\"\n",
    "\n",
    "from osgeo import gdal\n",
    "gdal.AllRegister()\n",
    "\n",
    "drivers = [gdal.GetDriver(i).GetDescription() for i in range(gdal.GetDriverCount())]\n",
    "print(\"JP2OpenJPEG\" in drivers)\n",
    "print(\"JP2KAK\" in drivers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e441b-492d-4d96-a027-d165ff30858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from odc.stac import load\n",
    "from pystac_client import Client\n",
    "from shapely.geometry import mapping, shape, MultiPolygon, Polygon, box\n",
    "from rasterio.features import geometry_mask\n",
    "import rasterio\n",
    "from geocube.api.core import make_geocube\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from cuml import RandomForestClassifier\n",
    "import cupy as cp\n",
    "import rioxarray \n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "from tqdm import tqdm  # for progress bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db364e86-e7a6-49b7-b3c9-8b8f6ac6ba37",
   "metadata": {},
   "source": [
    "#### Define AOI — Vanuatu Coastal Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c993f7-c663-4c7d-93e3-0a9103ae21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load province boundaries of Vanuatu\n",
    "provinces = gpd.read_file(\"./2016_phc_vut_pid_4326.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a010f-2837-455a-8054-8047bf484b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4efeda2-462f-4ace-b397-48f838bb4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces.iloc[-1].geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f241ceb2-b225-4fdb-bf0c-69a8706279ed",
   "metadata": {},
   "source": [
    "Buffer one province for demonstration. We'll use a subset of a province for this lesson, as we'll be using a time series ehich consumes more memory than a single timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c07d3-f1fe-4f0e-8b48-8507aa703877",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROVINCE = \"TAFEA\"\n",
    "DATERANGE_START = \"2020-06-01\"\n",
    "DATERANGE_END = \"2020-08-30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd87c6d-1caf-4048-806f-d8cdc18c7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject to meters\n",
    "province_proj = provinces.to_crs(epsg=32759) # UTM for Vanuatu\n",
    "\n",
    "# Get the boundary (coastline)\n",
    "coastline_proj = province_proj.boundary\n",
    "\n",
    "# Buffer outward\n",
    "full_buffer = coastline_proj.buffer(4000)  # 1000 meters\n",
    "\n",
    "# Subtract the original geometry to get *only the outer shell*\n",
    "external_only = full_buffer.difference(province_proj.geometry)\n",
    "\n",
    "# Back to lat/lon\n",
    "external_only_latlon = external_only.to_crs(epsg=4326)\n",
    "\n",
    "# Filter to one province (e.g., TORBA)\n",
    "province_match = provinces[provinces[\"pname\"] == PROVINCE]\n",
    "external_match = external_only_latlon.loc[province_match.index].iloc[0]\n",
    "\n",
    "# Ensure MultiPolygon, then get smallest\n",
    "geom = external_match\n",
    "\n",
    "# Get the medium sized island for this province\n",
    "if isinstance(geom, MultiPolygon):\n",
    "    # Sort polygons by area\n",
    "    sorted_polys = sorted(geom.geoms, key=lambda p: p.area)\n",
    "    n = len(sorted_polys)\n",
    "    median_index = n // 2  # Integer division\n",
    "\n",
    "    # If even number of polygons, pick the lower-middle one\n",
    "    selected = sorted_polys[median_index - 1] if n % 2 == 0 else sorted_polys[median_index]\n",
    "else:\n",
    "    selected = geom  # If it's just a single Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58a4746-4c3d-46c2-a15a-2aa9e8c3d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d8a161-eece-4b2c-a5a9-cfec576cf797",
   "metadata": {},
   "source": [
    "#### Search STAC for Sentinel-2 L1C Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e84b3-84bf-4b49-8890-1ad6d2fbe4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to STAC API\n",
    "stac = Client.open(\"https://earth-search.aws.element84.com/v1\") \n",
    "# https://earth-search.aws.element84.com/v1/collections/sentinel-2-l1c\n",
    "\n",
    "# Search for Sentinel-2 L1C within the reef buffer\n",
    "items_l1c = stac.search(\n",
    "    collections=[\"sentinel-2-l1c\"],\n",
    "    intersects=selected,\n",
    "    datetime=f\"{DATERANGE_START}/{DATERANGE_END}\",\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 20}}\n",
    ").item_collection()\n",
    "\n",
    "# Search for Sentinel-2 L2A within the reef buffer to obtain the LCL band for cloud masking\n",
    "items_l2a = stac.search(\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    intersects=selected,\n",
    "    datetime=f\"{DATERANGE_START}/{DATERANGE_END}\",\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 20}}\n",
    ").item_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd53f5dd-c87c-454a-a28c-bdd56d92c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(items_l1c), len(items_l2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa2802-0674-4d22-977d-1a865fd8a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_l1c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0c93a-3f2d-4cb3-84af-f7d9a5ae08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(item):\n",
    "    dt = item.datetime.replace(microsecond=0)  # drop microseconds\n",
    "    tile = item.properties.get(\"sentinel:tile_id\")\n",
    "    return (dt, tile)\n",
    "    \n",
    "# Build set of L2A (datetime, tile) keys\n",
    "l2a_keys = {get_key(item) for item in items_l2a}\n",
    "\n",
    "# Filter L1C items to only those that have matching keys in L2A\n",
    "items_l1c_filtered = [item for item in items_l1c if get_key(item) in l2a_keys]\n",
    "\n",
    "print(f\"Filtered L1C items: {len(items_l1c_filtered)} of {len(items_l1c)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa09e6d-5d5e-4c42-9220-558a1e148d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of (datetime, tile) from L1C\n",
    "l1c_keys = {get_key(item) for item in items_l1c_filtered}\n",
    "\n",
    "# Filter L2A items using the same key\n",
    "items_l2a_matched = [\n",
    "    item for item in items_l2a\n",
    "    if get_key(item) in l1c_keys\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e22c0b-beda-4e8b-b930-8d0920fab259",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(items_l1c_filtered):\n",
    "    print(i, get_key(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b5771-fb62-4f04-8384-cd0c3d2243f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(items_l2a_matched):\n",
    "    print(i, get_key(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78cd955-3541-49a2-b8f0-21280c57e8a1",
   "metadata": {},
   "source": [
    "#### Load Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dab3b4-b4b9-4a16-989a-3670cf46753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_l1c = load(\n",
    "    items_l1c_filtered,\n",
    "    bands=[\"blue\", \"green\", \"red\", \"nir08\", \"rededge1\", \"swir16\"], #\"rededge2\", \"rededge3\", \"swir22\"\n",
    "    crs=\"EPSG:32759\",  # UTM zone for Vanuatu\n",
    "    resolution=10,\n",
    "    #chunks={'x': 1024, 'y': 1024, 'bands': -1, 'time': -1}, #{\"time\": 1},\n",
    "    bbox=selected.bounds #aoi.total_bounds  # constrain to buffered coastline\n",
    ")\n",
    "\n",
    "ds_l2a = load(\n",
    "    items_l2a_matched,\n",
    "    bands=[\"blue\", \"green\", \"red\", \"scl\"],\n",
    "    crs=\"EPSG:32759\",  # UTM zone for Vanuatu\n",
    "    resolution=10,\n",
    "    #chunks={'x': 1024, 'y': 1024, 'bands': -1, 'time': -1}, #{\"time\": 1},\n",
    "    bbox=selected.bounds #aoi.total_bounds  # constrain to buffered coastline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f38bd-e737-48d6-b0fa-e724239145f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_l2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e07a1d-8eaa-42f1-aafa-747feb9cae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject the coastal buffer to match the dataset CRS\n",
    "buffer_gdf = gpd.GeoDataFrame(geometry=[selected], crs=\"EPSG:4326\")\n",
    "buffer_proj = buffer_gdf.to_crs(ds_l1c.rio.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcefe57-2a77-44b8-a10d-3995e8f7ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary mask: True = outside buffer, False = inside\n",
    "mask_l1c = geometry_mask(\n",
    "    geometries=[mapping(buffer_proj.iloc[0].geometry)],\n",
    "    transform=ds_l1c.odc.transform,\n",
    "    out_shape=(ds_l1c.sizes[\"y\"], ds_l1c.sizes[\"x\"]),\n",
    "    invert=True  # We want True = inside the buffer\n",
    ")\n",
    "\n",
    "mask_l2a = geometry_mask(\n",
    "    geometries=[mapping(buffer_proj.iloc[0].geometry)],\n",
    "    transform=ds_l2a.odc.transform,\n",
    "    out_shape=(ds_l2a.sizes[\"y\"], ds_l2a.sizes[\"x\"]),\n",
    "    invert=True  # We want True = inside the buffer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90fac2a-7ea0-49a6-8d9e-2ced5925174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataArray\n",
    "mask_xr_l1c = xr.DataArray(\n",
    "    mask_l1c,\n",
    "    dims=(\"y\", \"x\"),\n",
    "    coords={\"y\": ds_l1c.y, \"x\": ds_l1c.x}\n",
    ")\n",
    "\n",
    "mask_xr_l2a = xr.DataArray(\n",
    "    mask_l2a,\n",
    "    dims=(\"y\", \"x\"),\n",
    "    coords={\"y\": ds_l2a.y, \"x\": ds_l2a.x}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06278d-8192-4a00-8be3-85a7f791db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_masked_l1c = ds_l1c.where(mask_xr_l1c)\n",
    "ds_masked_l2a = ds_l2a.where(mask_xr_l2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05031269-a4e8-494c-8d58-6dda02dd3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cloud class codes\n",
    "cloud_classes = [8, 9, 10]\n",
    "\n",
    "# Create a mask: True = valid (non-cloud), False = cloud\n",
    "valid_mask = ~ds_l2a[\"scl\"].isin(cloud_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16543a62-8d64-4f9a-8691-be7cecfa89fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_masked = ds_masked_l1c[[\"blue\", \"green\", \"red\", \"nir08\", \"rededge1\", \"swir16\"]].where(valid_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31c16f-99fd-4b5c-b967-fe7c39b7bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd9a08a-b763-47e9-ae36-3f851f3ce7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose time slice and scale reflectance\n",
    "ds_rgb = ds_masked_l2a[[\"red\", \"green\", \"blue\"]] #.isel(time=0)\n",
    "scale = ds_rgb.to_array().quantile(0.99).item() #.compute().item()  # auto-scale to 99th percentile\n",
    "ds_rgb = (ds_rgb / scale).clip(0, 1)\n",
    "\n",
    "# Stack and plot\n",
    "rgb = xr.concat([ds_rgb[\"red\"], ds_rgb[\"green\"], ds_rgb[\"blue\"]], dim=\"band\")\n",
    "rgb = rgb.assign_coords(band=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "rgb.hvplot.rgb(x=\"x\", y=\"y\", bands=\"band\", width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f53e5-1cba-474a-83e0-8e53f6eea902",
   "metadata": {},
   "source": [
    "## Top of Atmosphere (TOA) vs. Surface Reflectance & Atmospheric Correction\n",
    "**TOA reflectance** refers to the reflectance values measured by a satellite sensor **before any correction for atmospheric effects**. It represents the **radiance reaching the sensor at the top of the atmosphere**, and includes contributions from:\n",
    "\n",
    "* Direct solar reflectance from the surface,\n",
    "* **Scattering by atmospheric molecules** (Rayleigh scattering),\n",
    "* **Scattering by aerosols** and haze,\n",
    "* **Reflection from clouds** and surrounding areas.\n",
    "\n",
    "> **Sentinel-2 Level-1C** products are provided in TOA reflectance.\n",
    "\n",
    "**Surface Reflectance** is the fraction of incoming solar radiation **reflected by the Earth's surface**, as it would appear **if the atmosphere were not present**. It represents the true reflectance of land, water, or vegetation and is more reliable for quantitative analysis.\n",
    "\n",
    "> **Sentinel-2 Level-2A** products are atmospherically corrected to surface reflectance.\n",
    "\n",
    "Sentinel-2 Level-2A data is produced using the Sen2Cor processor, which performs atmospheric correction to derive surface reflectance from top-of-atmosphere (TOA) reflectance. It was designed primarily for land surfaces — not water. We'll come back to this in a moment.\n",
    "\n",
    "**Atmospheric correction** is the process of **removing atmospheric effects** from TOA reflectance to estimate **surface reflectance**. It compensates for:\n",
    "\n",
    "* **Scattering** (blue light by molecules, haze),\n",
    "* **Absorption** (by gases like water vapor, ozone, CO₂),\n",
    "* **Aerosols** (dust, smoke, sea salt).\n",
    "\n",
    "There are two main types:\n",
    "\n",
    "* **Empirical methods**: e.g., **Dark Object Subtraction (DOS)**, based on scene content.\n",
    "* **Physics-based methods**: e.g., **Sen2Cor**, **6S**, or **ACOLITE**, which use radiative transfer models and ancillary data (e.g., aerosol optical thickness).\n",
    "\n",
    "Water bodies have unique optical properties that make atmospheric correction far more complex:\n",
    "\n",
    "1. Low Reflectance (Dark Target Problem)\n",
    "* Water reflects very little sunlight, especially in the visible and near-infrared.\n",
    "* This makes it hard to distinguish water signal from atmospheric scattering, leading to unstable or noisy surface reflectance values.\n",
    "* Overcorrected water pixels may even appear as negative reflectance, which is physically meaningless.\n",
    "\n",
    "2. High Sensitivity to Atmospheric Effects\n",
    "* Even small amounts of aerosols, thin clouds, or Rayleigh scattering can dominate the signal received from water.\n",
    "* Sen2Cor is tuned for land reflectance properties, and may overcorrect these subtle signals in aquatic environments.\n",
    "\n",
    "3. Incorrect Assumptions\n",
    "* Sen2Cor assumes a Lambertian (diffuse) surface, which is true for land but not for water, which reflects sunlight specularly (like a mirror).\n",
    "* It also uses land-based visibility and elevation models that don’t apply well to open water.\n",
    "\n",
    "4. No Water-Specific Tuning\n",
    "* Sen2Cor doesn’t use water-leaving radiance models or bidirectional reflectance functions (BRDF) specific to aquatic systems.\n",
    "* It lacks aerosol correction schemes optimized for open water, unlike ocean color processors (e.g., ACOLITE or C2RCC).\n",
    "\n",
    "#### What To Use Instead Over Water?\n",
    "For more reliable atmospheric correction over water, use:\n",
    "\n",
    "* ACOLITE – Optimized for coastal and inland waters.\n",
    "\n",
    "* C2RCC (Case 2 Regional CoastColour) – Designed for complex waters with variable optical properties.\n",
    "\n",
    "* Dark Object Subtraction (DOS) – A simple, empirical method suitable for ocean scenes with no clouds and minimal aerosols.\n",
    "\n",
    "Today, we'll use DOS as it doesn't require us to download any external software. IT isn't perfect for this task, as we'll explain in next, but it does well enough to be suitable for this exercise.\n",
    "\n",
    "### Dark Object Subtraction\n",
    "\n",
    "**Dark Object Subtraction (DOS)** is a simple and widely used atmospheric correction method that estimates and removes the effects of atmospheric scattering in satellite imagery. It is particularly useful for correcting **Sentinel-2 Level-1C (Top-of-Atmosphere reflectance)** imagery in oceanic or coastal environments.\n",
    "\n",
    "The core idea behind DOS is that certain \"dark objects\" in the scene—such as deep, clear water or dense vegetation—should theoretically have **near-zero reflectance** in some bands (especially the blue and shortwave bands). Any non-zero signal observed in these dark areas is attributed to **path radiance** (light scattered by the atmosphere).\n",
    "\n",
    "#### How It Works\n",
    "\n",
    "1. **Identify dark pixels**: Find the minimum (or low-percentile, e.g., 1%) reflectance values over dark surfaces, usually in the **blue band (Band 2)** or **coastal aerosol band (Band 1)**.\n",
    "2. **Estimate path radiance**: Assume this value represents atmospheric scattering (haze, Rayleigh scattering).\n",
    "3. **Subtract offset**: Subtract this value from all pixels in the scene for each band to estimate surface reflectance:\n",
    "\n",
    "   ```\n",
    "   ρ_surface = ρ_TOA - ρ_min\n",
    "   ```\n",
    "4. **Clip negatives**: Any resulting negative reflectance values are set to zero.\n",
    "\n",
    "#### Application Over the Ocean\n",
    "\n",
    "* **Clear deep water** serves as an ideal dark object.\n",
    "* Works best in **clear-sky, deep-ocean** conditions where water reflectance is minimal.\n",
    "* Helps reduce haze and Rayleigh scattering impacts in **shorter wavelengths** (e.g., blue, green).\n",
    "* Less effective in **turbid, shallow, or coastal** waters where bottom reflectance or suspended particles are present.\n",
    "* Simple, fast, and does not require external atmospheric data.\n",
    "* Useful for preprocessing imagery in remote areas with limited ancillary data.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "* Assumes perfect dark targets exist in the scene.\n",
    "* Overcorrects in bright or turbid water conditions.\n",
    "* Ignores adjacency effects and variable atmospheric thickness.\n",
    "* Does not correct for absorption effects (e.g., water vapor, aerosols)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc00dc-ea0c-4027-ac50-fa857f360da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dark_object_subtraction(band, percentile=1, max_subtract=0.05):\n",
    "    \"\"\"\n",
    "    Apply DOS safely to float32 reflectance images.\n",
    "    Caps subtraction to prevent overcorrection.\n",
    "    \"\"\"\n",
    "    # Sample spatially\n",
    "    sample = band.isel(x=slice(None, None, 10), y=slice(None, None, 10))\n",
    "    \n",
    "    # Compute dark object reflectance\n",
    "    dark_val = sample.quantile(percentile / 100.0, skipna=True).compute()\n",
    "    dark_val = min(max(dark_val.item(), 0.0), max_subtract)\n",
    "    print(\"Dark value:\", dark_val)\n",
    "\n",
    "    # Apply DOS (clip only min to avoid upward clipping)\n",
    "    return (band - dark_val).clip(min=0)\n",
    "\n",
    "\n",
    "def correct_dataset(ds, bands=[\"blue\", \"green\", \"red\", \"nir08\", \"rededge1\", \"swir16\"]):\n",
    "    corrected = {}\n",
    "    for b in bands:\n",
    "        corrected[b] = dark_object_subtraction(ds[b])\n",
    "    return xr.Dataset(corrected, coords=ds.coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e984729-32e4-4f5e-85d9-7632998bbc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentinel-2 L1C data must be scaled from 0–10000 to 0–1 reflectance before applying dark object subtraction\n",
    "ds_scaled = ds_masked / 10000.0\n",
    "# Correct each timestep and concatenate\n",
    "corrected_list = [\n",
    "    correct_dataset(ds_scaled.isel(time=t), bands=[\"blue\", \"green\", \"red\", \"nir08\", \"rededge1\", \"swir16\"])\n",
    "    for t in range(ds_scaled.sizes['time'])\n",
    "]\n",
    "\n",
    "# Combine along time\n",
    "ds_corrected = xr.concat(corrected_list, dim='time')\n",
    "ds_corrected['time'] = ds_scaled['time']  # Reassign time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec814db7-2590-4ffa-906c-074632e7afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output ranges\n",
    "vals = ds_corrected[\"blue\"].isel(time=0).values\n",
    "vals_clean = vals[np.isfinite(vals)]\n",
    "\n",
    "print(\"Unique:\", np.unique(vals_clean))\n",
    "print(\"Min:\", vals_clean.min())\n",
    "print(\"Max:\", vals_clean.max())\n",
    "print(\"Proportion of 1.0 values:\", (vals_clean == 1.0).sum() / len(vals_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b142bb2-e0c7-478f-bd66-e17139de164b",
   "metadata": {},
   "source": [
    "#### Visualize the L1C true color imagery before atmospheric correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b287f644-23c0-411d-9f6a-97abc125766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and concatenate RGB bands\n",
    "ds_rgb = ds_masked[[\"red\", \"green\", \"blue\"]]\n",
    "rgb = xr.concat([ds_rgb[b] for b in [\"red\", \"green\", \"blue\"]], dim=\"band\")\n",
    "rgb = rgb.assign_coords(band=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "# Sampled quantile scaling\n",
    "scale = rgb.quantile(0.99, dim=(\"x\", \"y\"), skipna=True).compute()\n",
    "rgb_scaled = (rgb / scale).clip(0, 1)\n",
    "\n",
    "# Plot\n",
    "rgb_scaled.hvplot.rgb(x=\"x\", y=\"y\", bands=\"band\", width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c209279-bc03-4173-843a-8041d030cc5a",
   "metadata": {},
   "source": [
    "#### Visualize the L1C true color imagery after atmospheric correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41df7ab-e912-47f5-9f96-24f4da3431e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and concatenate RGB bands\n",
    "ds_rgb = ds_corrected[[\"red\", \"green\", \"blue\"]]\n",
    "rgb = xr.concat([ds_rgb[b] for b in [\"red\", \"green\", \"blue\"]], dim=\"band\")\n",
    "rgb = rgb.assign_coords(band=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "# Sampled quantile scaling\n",
    "scale = rgb.quantile(0.99, dim=(\"x\", \"y\"), skipna=True).compute()\n",
    "rgb_scaled = (rgb / scale).clip(0, 1)\n",
    "\n",
    "# Plot\n",
    "rgb_scaled.hvplot.rgb(x=\"x\", y=\"y\", bands=\"band\", width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058264a-d14a-4745-a7a6-4a8d97a4e7b0",
   "metadata": {},
   "source": [
    "### Compute Reef Health Indicators\n",
    "\n",
    "The **Blue-Green Index (BGI)** is a spectral index used primarily in aquatic and coastal remote sensing to help discriminate benthic habitats (like coral reefs, seagrass, sand) and assess water properties ([Bannari et al., 2022](https://os.copernicus.org/articles/18/361/2022/)). It leverages the difference and sum of the **blue** and **green** spectral bands.\n",
    "\n",
    "#### Formula\n",
    "\n",
    "$$\n",
    "\\text{BGI} = {\\text{Blue} - \\text{Green}}\n",
    "$$\n",
    "\n",
    "* Calculated using surface reflectance values.\n",
    "\n",
    "\n",
    "#### Interpretation of BGI values\n",
    "$D$ = difference\n",
    "\n",
    "  * **Positive** $D>0$: Blue reflectance > Green → More blue reflectance → indicates clear water, possibly healthy coral or bright sandy substrate.\n",
    "  * **Negative** $D<0$: Green > Blue → often **shallow water**, **vegetation**, or **sediment** that boosts green. May suggest turbid water, algal blooms, or seagrass.\n",
    "  * **Zero** $D=0$: equal blue/green reflectance.\n",
    "\n",
    "#### How BGI helps with coral reefs\n",
    "\n",
    "* **Differentiates benthic substrates:** Coral, seagrass, algae, sand, and bare substrate often have distinct blue and green reflectance signatures, so BGI can help separate these classes.\n",
    "* **Highlights shallow water features:** Coral reefs usually occur in shallow, clear water where blue and green light penetrates well, making BGI sensitive to benthic composition.\n",
    "* **Tracks changes over time:** By analyzing BGI time series, you can detect changes in reef cover, algal blooms, sedimentation, or coral bleaching events affecting reflectance.\n",
    "\n",
    "#### Limitations and considerations\n",
    "\n",
    "* **Scale-sensitive**: Sensitive to illumination, sensor gain, and shadows — not standardized across conditions. A difference of 0.1 at low reflectance (e.g. 0.15–0.05) is not the same \"contrast\" as 0.1 at high reflectance (0.80–0.70), but raw $D$ treats them identically.\n",
    "* Usually masked to water pixels (e.g., using land/water masks or cloud masks).\n",
    "* Values should be interpreted relative to local calibration or ground truth.\n",
    "* **Water column effects:** Water depth, turbidity, and dissolved materials affect blue and green light differently, potentially confounding BGI values.\n",
    "* **Atmospheric correction needed:** Accurate surface reflectance is essential for reliable BGI values, especially over water.\n",
    "* **Not a direct health measure:** BGI reflects substrate and water color but not coral health metrics like bleaching directly. It is an indirect indicator.\n",
    "* **Supplement with other indices and data:** Combine BGI with other indices (e.g., NDVI for algae, bathymetry data, or hyperspectral data) for better reef monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb2e6b-3a40-41d5-83a7-763aa231af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bgi(ds):\n",
    "    return (ds[\"blue\"] - ds[\"green\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b303831-0f7c-4b74-ab88-8afade4d68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BGI for every timestamp\n",
    "bgi_list = [\n",
    "    compute_bgi(ds_corrected.isel(time=t))\n",
    "    for t in range(ds_corrected.sizes['time'])\n",
    "]\n",
    "\n",
    "# Combine along time\n",
    "bgi = xr.concat(bgi_list, dim='time')\n",
    "bgi['time'] = bgi['time']  # Reassign time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e0447d-bf30-468f-8a7f-bb94499adf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize corrected BGI\n",
    "bgi.hvplot.image(x=\"x\", y=\"y\", cmap=\"viridis\", width=600, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d5cd8-3d4c-4961-906e-83c0d4128958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output ranges\n",
    "vals = bgi.values\n",
    "vals_clean = vals[np.isfinite(vals)]\n",
    "\n",
    "#print(\"Unique:\", np.unique(vals_clean))\n",
    "print(\"Min:\", vals_clean.min())\n",
    "print(\"Max:\", vals_clean.max())\n",
    "print(\"Proportion of 1.0 values:\", (vals_clean == 1.0).sum() / len(vals_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f8e43-44c2-466e-9589-72e6061844b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask invalid values\n",
    "bgi = bgi.where((bgi >= -1) & (bgi <= 1))  # BGI is a normalized index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7bc07-4798-4290-9bd2-33e82c403115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to GeoTIFF\n",
    "bgi.rio.to_raster(f\"bgi_{PROVINCE}_{DATERANGE_START}_{DATERANGE_END}.tif\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc60d7d-7402-4d18-a07b-9be2713ea389",
   "metadata": {},
   "source": [
    "Because the Blue Green index has such limitations, we can normalize it to make it robust to lighting changes, atmospheric variation, and sensor inconsistencies — making it more reliable for time-series analysis or cross-scene comparisons. Coral bleaching often leads to whitening, reducing pigment (chlorophyll) and increasing reflectance in the visible spectrum (especially blue and green). A sudden rise in visible reflectance and drop in red-edge/NIR may indicate bleaching.\n",
    "\n",
    "The **normalized blue green index** uses a **normalized difference** of the blue and green bands to detect coral bleaching, which manifests as a spectral signature change in shallow waters. This is a form of a **Normalized Difference Index** (like NDVI), designed to highlight spectral changes in coral reefs:\n",
    "\n",
    "$$\n",
    "\\text{Normalized Blue Green Index} = \\frac{Blue - Green}{Blue + Green}\n",
    "$$\n",
    "\n",
    "* **Healthy coral** reflects more in the **green** spectrum and absorbs more **blue** light.\n",
    "* **Bleached coral** loses pigmentation and structure, becoming brighter in **blue**, reducing the green–blue contrast.\n",
    "\n",
    "#### Interpretation of NBGI values\n",
    "\n",
    "* **Positive** ($0< \\text{NBGI}\\le1$): Blue dominates relative to total signal → likely **clearer/deeper water** or substrates with strong blue reflectance (e.g., bleached coral).\n",
    "* **Negative** ($-1\\le \\text{NBGI}<0$): Green dominates → shallow water, benthic vegetation (seagrass, algae), or sediment.\n",
    "* **Zero** ($\\text{NBGI}=0$): equal contribution of blue and green.\n",
    "\n",
    "* **Higher index values** → likely **healthy coral** (stronger green reflectance).\n",
    "* **Lower index values** → potential **bleached coral** (higher blue reflectance).\n",
    "\n",
    "#### Advantages\n",
    "* **Normalized**: automatically adjusts for overall brightness—sun angle, water depth, sensor gain—so values are **directly comparable** across images and times.\n",
    "* **Bounded**: easy to interpret thresholds (e.g., $\\text{NBGI}<−0.2$ for dense vegetation, $\\text{NBGI}>0.2$ for clear water).\n",
    "* **Contrast-enhancing**: emphasizes relative difference rather than absolute magnitude.\n",
    "\n",
    "\n",
    "#### Considerations:\n",
    "* **Only works in shallow, clear water** — turbid water or shadows can affect accuracy.\n",
    "* Requires masking **clouds**, **deep water**, and **land** first.\n",
    "* You can couple it with red edge or NIR bands, or other indices like:\n",
    "\n",
    "  * **NDVI**\n",
    "  * **Red-Edge Chlorophyll Index**\n",
    "  * **Turbidity Index** (Blue/SWIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acabcb88-1027-4eb3-9a88-777189bef7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nbgi(ds):\n",
    "    return (ds[\"blue\"] - ds[\"green\"]) / (ds[\"blue\"] + ds[\"green\"])  # Simplified spectral ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e9f72-addc-4588-952f-1fbe883639af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BGI for every timestamp\n",
    "nbgi_list = [\n",
    "    compute_nbgi(ds_corrected.isel(time=t))\n",
    "    for t in range(ds_corrected.sizes['time'])\n",
    "]\n",
    "\n",
    "# Combine along time\n",
    "nbgi = xr.concat(nbgi_list, dim='time')\n",
    "nbgi['time'] = nbgi['time']  # Reassign time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59edd7f8-48b2-4923-9fe2-545cac1a216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output ranges\n",
    "vals = nbgi.values\n",
    "vals_clean = vals[np.isfinite(vals)]\n",
    "\n",
    "#print(\"Unique:\", np.unique(vals_clean))\n",
    "print(\"Min:\", vals_clean.min())\n",
    "print(\"Max:\", vals_clean.max())\n",
    "print(\"Proportion of 1.0 values:\", (vals_clean == 1.0).sum() / len(vals_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b3a2d5-24f6-4efd-a0a6-94874ade0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize corrected BGI\n",
    "nbgi.hvplot.image(x=\"x\", y=\"y\", cmap=\"viridis\", width=600, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760f279-9090-4b8b-ac6d-2aea4bbdeb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbgi.rio.to_raster(f\"nbgi_{PROVINCE}_{DATERANGE_START}_{DATERANGE_END}.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55dee2c-f8a3-4286-8268-7a99c3567c42",
   "metadata": {},
   "source": [
    "### Ground truth data integration and segmentation\n",
    "\n",
    "We will use a reef map provided by Vanuatu Bureau of Statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac385fa-a0f0-4b2f-87e7-bfdd1db330c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_gdf = gpd.read_file('Vanuatu reefs IMARS.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b287a086-b519-4c81-85fa-1310fd401eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce354d-cecc-4bdd-ba5e-bad521b5e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "benthic_gdf.REEF.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95c2db-660a-4f70-a4aa-6493de1fcce6",
   "metadata": {},
   "source": [
    "The reef map is a vector polygon dataset. We are rasterizing it to use as labels for the blue-green index pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b2614-2170-4622-98e8-949e55da953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = nbgi.x.size, nbgi.y.size\n",
    "\n",
    "benthic_gdf_rp = benthic_gdf.to_crs(epsg=nbgi.rio.crs.to_epsg())\n",
    "\n",
    "# Define the resolution and bounds based on BGI features\n",
    "resolution = nbgi.rio.resolution()\n",
    "bounds_test = nbgi.rio.bounds()\n",
    "\n",
    "unique_classes = benthic_gdf['REEF'].unique()\n",
    "\n",
    "raster_bounds = box(*nbgi.rio.bounds())\n",
    "benthic_gdf_select = benthic_gdf_rp[benthic_gdf_rp.intersects(raster_bounds)]\n",
    "\n",
    "print(f\"Before: {len(benthic_gdf_rp)} | After: {len(benthic_gdf_select)}\")\n",
    "\n",
    "# Rasterize the vector dataset to match the BGI image\n",
    "rasterized_labels_benthic = make_geocube(\n",
    "    vector_data=benthic_gdf_select,\n",
    "    measurements=[\"REEF\"], \n",
    "    like=nbgi,  # Align with the features dataset\n",
    ")\n",
    "\n",
    "print(\"rasterized_labels_benthic: \", rasterized_labels_benthic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf313ab-23eb-4df1-be56-3d79ccd0c426",
   "metadata": {},
   "source": [
    "#### Live Coral vs. Algae/Sand\n",
    "\n",
    "Live coral has unique reflectance in the red-edge and NIR bands.\n",
    "\n",
    "Useful Bands:\n",
    "\n",
    "* Red Edge\n",
    "\n",
    "* Near Infrared\n",
    "\n",
    "* Short Wave Infrared (for benthic type separation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3759498-f8ce-432a-b17c-03e5ffe91edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_stack = xr.concat([\n",
    "    ds_corrected[\"rededge1\"],\n",
    "    #ds_corrected[\"rededge2\"],\n",
    "    #ds_corrected[\"rededge3\"],\n",
    "    ds_corrected[\"nir08\"],\n",
    "    ds_corrected[\"swir16\"],\n",
    "    #ds_corrected[\"swir22\"],\n",
    "    nbgi\n",
    "], dim=\"band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452b21ed-de11-4fda-b78d-415e8287d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399dbf9-fde3-49b2-83ba-63bb08684127",
   "metadata": {},
   "source": [
    "Flatten the features and newly rasterized labels for use with a random forest classifier. We will use the first timestamp as features for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16df77-c861-457d-ae6c-4c2f2bf1df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = features_stack.isel(time=0).stack(flattened_pixel=(\"y\", \"x\")).fillna(0)\n",
    "features = features_stack.isel(time=0).transpose(\"y\", \"x\", \"band\").stack(flattened_pixel=(\"y\", \"x\")).transpose(\"flattened_pixel\", \"band\").fillna(-9999)\n",
    "labels = rasterized_labels_benthic.stack(flattened_pixel=(\"y\", \"x\")).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c2f12c-be42-4b14-853b-3057a8326639",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.to_array().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8367c272-0832-4003-8c58-78f00b2edf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867a740-10b3-4d79-a708-a0f35b0e6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d502449-df66-4d85-a40e-c58b2c31dfc9",
   "metadata": {},
   "source": [
    "#### Data Splitting\n",
    "Now that we have the arrays flattened, we can split the datasets into training and testing partitions. We will reserve 80 percent of the data for training, and 20 percent for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f8458-6c88-4843-9739-3a92cef25fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features.data, labels, test_size=0.2, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f575c4e2-7814-4408-bdd9-4209156f3821",
   "metadata": {},
   "source": [
    "Ensure all labels are in each partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ccde48-677b-4fdd-ab78-4b3675dbe338",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train), np.unique(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c486e-2378-46d0-9e57-ed8baf50bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcde110d-4c24-4cc5-baa9-6dde0ee1a101",
   "metadata": {},
   "source": [
    "Add the samples dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffcd26-100e-4573-8db9-e5a27df2f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.data.reshape(-1, 1)\n",
    "#X_test = X_test.data.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eebe44-5607-46a5-b7c0-274ab1f01976",
   "metadata": {},
   "source": [
    "Now we will set up a small [random forest classifider](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) with 10 trees. We use a [seed](https://towardsdatascience.com/why-do-we-set-a-random-state-in-machine-learning-models-bb2dc68d8431) (`random_state`) to ensure reproducibility. Calling the `.fit()` method on the classifier will initiate training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b9c88-a2dd-48f0-bee3-2017fb0c8b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42) #n_estimators=10\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1bbb5b-d5e5-4ab6-9cf7-875ee20120a7",
   "metadata": {},
   "source": [
    "Once the classifier is finished training, we can use it to make predictions on our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0138d-172b-454d-9e59-6b00aa73a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the classifier\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99146808-de20-42cf-bb40-42194a9a5c0d",
   "metadata": {},
   "source": [
    "It's important to know how well our classifier performs relative to the true labels (`y_test`). For this, we can calculate the [accuracy metric](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) to measure agreement between the true and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edbf435-eb9a-4f79-a906-d94050b0bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd9ae8c-8949-417c-b13e-bf743411b0fa",
   "metadata": {},
   "source": [
    "We can also produce a [classification report](https://scikit-learn.org/1.7/modules/generated/sklearn.metrics.classification_report.html)\n",
    "to check the precision, recall and F1 scores for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef81e8b-35ef-4782-bac9-89683081f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca06e8d-5147-4b2d-bef7-5586d596a39c",
   "metadata": {},
   "source": [
    "We can also plot a confusion matrix to explore per-class performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567896e-0745-42a1-b637-3920f7fbbe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true=y_test, y_pred=y_pred, normalize=\"true\", values_format=\".2f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf567b0-4c70-439e-b480-7dc67468ee0c",
   "metadata": {},
   "source": [
    "Save the model to file so that it can be loaded and reused again without needing to repeat training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b0c88-dfb8-45bc-9580-13cefeba22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "joblib.dump(clf, f\"rf_vanuatu_coral_{PROVINCE}_{DATERANGE_START}_{DATERANGE_END}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a6b09b-aeb9-4db1-8493-3f7a266467dc",
   "metadata": {},
   "source": [
    "If we want to generate predictions for the entire dataset in order to plot a map of predicted reefs for the entire area of interest, we can do this using the test province dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca640be-5c89-4abf-8744-a7b7e95c3ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_in_batches(model, X, batch_size=100000):\n",
    "    results = []\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        batch = X[i:i+batch_size]\n",
    "        pred = model.predict(batch)\n",
    "        results.append(pred)\n",
    "    return np.concatenate(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc88de2-a5d3-4311-8745-3506919c04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BGI for every timestamp\n",
    "pred_list = [\n",
    "    predict_in_batches(clf, features_stack.isel(time=t).transpose(\"y\", \"x\", \"band\")\n",
    "                .stack(flattened_pixel=(\"y\", \"x\")).transpose(\"flattened_pixel\", \"band\")\n",
    "                .fillna(0).data, batch_size=100000).reshape((height, width))\n",
    "    for t in range(ds_corrected.sizes['time'])\n",
    "]\n",
    "\n",
    "pred_list_xr = [xr.DataArray(data=predicted_map, coords=rasterized_labels_benthic.coords) for predicted_map\n",
    "                in pred_list]\n",
    "\n",
    "# Combine along time\n",
    "predictions = xr.concat(pred_list_xr, dim='time')\n",
    "predictions['time'] = features_stack['time']  # Reassign time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d75c3b-e2d3-48af-bfb9-aa3930ee3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.hvplot.image(height=600, rasterize=True, cmap=\"Set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6691c4-6509-4e7a-9cd1-4935d4ac6065",
   "metadata": {},
   "source": [
    "Vectorize and save the predicted reef map to a geojson file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10236413-01ad-4472-bb15-32c53ce7d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert array to int32\n",
    "compatible_array = predictions.astype(\"int32\")\n",
    "\n",
    "# Rasterize to polygons\n",
    "polygons = list(\n",
    "    rasterio.features.shapes(\n",
    "        compatible_array.values,\n",
    "        transform=compatible_array.rio.transform()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Convert to GeoDataFrame and filter for value == 1\n",
    "prediction_gdf = gpd.GeoDataFrame(\n",
    "    [{\"geometry\": shape(geom), \"value\": value} for geom, value in polygons if value == 1],\n",
    "    crs=\"EPSG:32759\"\n",
    ")\n",
    "\n",
    "# print unique values (should be [1])\n",
    "print(prediction_gdf.value.unique())\n",
    "\n",
    "# Save to GeoJSON\n",
    "prediction_gdf.to_file(\n",
    "    f\"./predicted_coral_{PROVINCE}_{DATERANGE_START}_{DATERANGE_END}.geojson\",\n",
    "    driver=\"GeoJSON\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752c4d1-c29c-437a-a585-538cc81a375d",
   "metadata": {},
   "source": [
    "### Time series analysis and change detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65466e06-15c4-4a7d-b108-a156b3d25584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple difference between two time points\n",
    "# Compare two specific time indices (e.g., first and last)\n",
    "reef_change = predictions.isel(time=-1) - predictions.isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f694b-4e84-4a8d-8157-ba488dc55d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reef_change.hvplot.image(height=600, rasterize=True, cmap=\"Set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bdd704-db90-411a-ad62-662f4f234b65",
   "metadata": {},
   "source": [
    "#### Trend analysis\n",
    "\n",
    "Now let's compute the **per-pixel linear trend over time** from the time series prediction maps.\n",
    "\n",
    "- `time_num` is a numeric time axis (e.g., `[0, 1, 2, ...]`) corresponding to each time step in the data.\n",
    "- The inner function `fit_linear_trend(y)` takes a 1D time series (one pixel's values across time) and:\n",
    "  - Masks out `NaN`s with `np.isfinite`.\n",
    "  - Fits a linear model (`np.polyfit`) only if there are at least 2 valid observations.\n",
    "  - Returns the **slope** of the best-fit line, representing the **rate of change over time**.\n",
    "  - Returns `NaN` if the fit fails or insufficient data exists.\n",
    "- `xr.apply_ufunc` applies `fit_linear_trend` to every pixel in the dataset using xarray's vectorized and parallelized infrastructure, preserving spatial dimensions and returning a new DataArray of trend values.\n",
    "\n",
    "This function is useful for detecting temporal changes (e.g., coral bleaching trends, vegetation decline, or urban expansion) on a per-pixel basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f191f-dbc5-45ff-83c0-c5487eb0d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_trend(da):\n",
    "    \"\"\"Fit linear trend per pixel over time, robust to NaNs and low data.\"\"\"\n",
    "\n",
    "    time_num = np.arange(da.sizes['time'])\n",
    "\n",
    "    def fit_linear_trend(y):\n",
    "        y = np.array(y)\n",
    "        valid_mask = np.isfinite(y)\n",
    "        if valid_mask.sum() < 2:  # Not enough data points to fit\n",
    "            return np.nan\n",
    "        try:\n",
    "            p = np.polyfit(time_num[valid_mask], y[valid_mask], deg=1)\n",
    "            return p[0]  # slope\n",
    "        except np.linalg.LinAlgError:\n",
    "            return np.nan\n",
    "\n",
    "    trend = xr.apply_ufunc(\n",
    "        fit_linear_trend,\n",
    "        da,\n",
    "        input_core_dims=[['time']],\n",
    "        vectorize=True,\n",
    "        dask='parallelized',\n",
    "        output_dtypes=[float]\n",
    "    )\n",
    "    return trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ca441-3264-4083-9f88-16d2476c707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reef_trend = calc_trend(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce30c0bd-77d0-488a-87a9-387aa8aa702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reef_trend.hvplot.image(height=600, rasterize=True, cmap=\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00b8d1-fe5b-49ca-b631-41a8f118c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and concatenate RGB bands\n",
    "ds_rgb = ds_corrected[[\"red\", \"green\", \"blue\"]]\n",
    "rgb = xr.concat([ds_rgb[b] for b in [\"red\", \"green\", \"blue\"]], dim=\"band\")\n",
    "rgb = rgb.assign_coords(band=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "# Sampled quantile scaling\n",
    "scale = rgb.quantile(0.99, dim=(\"x\", \"y\"), skipna=True).compute()\n",
    "rgb_scaled = (rgb / scale).clip(0, 1)\n",
    "\n",
    "# Plot\n",
    "rgb_scaled.hvplot.rgb(x=\"x\", y=\"y\", bands=\"band\", width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f653c24-e2fb-4f74-8a8e-079aa114c6cb",
   "metadata": {},
   "source": [
    "#### Threshold the change to detect significant reef change\n",
    "Track loss in reflectance in blue/green bands or increase in brightness. Bleached coral appears whiter and brighter due to algae loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2726780-da9f-47a6-9e2d-e7e628bd114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_trend = xr.where(np.abs(reef_trend) > 0.01, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d052973c-6f50-4cb9-ab2e-2c01d2649d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_trend.hvplot.image(height=600, rasterize=True, cmap=\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2716b3-ca1c-47a0-ad8b-223aa579f6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
